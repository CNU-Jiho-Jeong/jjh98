{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DenseNet(Tensorflow).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNsZl4C3JLv1e6roxUA6adk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"BzYKSuITj5hU","executionInfo":{"status":"error","timestamp":1661490793792,"user_tz":-540,"elapsed":2980,"user":{"displayName":"정지호","userId":"16891067989582209865"}},"outputId":"de47a8e2-275c-43b2-eda7-4698131e3514"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-96bfce3d52fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersionAwareLayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.applications'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","# pylint: disable=invalid-name\n","\"\"\"DenseNet models for Keras.\n","Reference:\n","  - [Densely Connected Convolutional Networks](\n","      https://arxiv.org/abs/1608.06993) (CVPR 2017)\n","\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","from tensorflow.python.keras import backend\n","from tensorflow.python.keras.applications import imagenet_utils\n","from tensorflow.python.keras.engine import training\n","from tensorflow.python.keras.layers import VersionAwareLayers\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.python.keras.utils import layer_utils\n","from tensorflow.python.lib.io import file_io\n","from tensorflow.python.util.tf_export import keras_export\n","\n","\n","BASE_WEIGTHS_PATH = ('https://storage.googleapis.com/tensorflow/'\n","                     'keras-applications/densenet/')\n","DENSENET121_WEIGHT_PATH = (\n","    BASE_WEIGTHS_PATH + 'densenet121_weights_tf_dim_ordering_tf_kernels.h5')\n","DENSENET121_WEIGHT_PATH_NO_TOP = (\n","    BASE_WEIGTHS_PATH +\n","    'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5')\n","DENSENET169_WEIGHT_PATH = (\n","    BASE_WEIGTHS_PATH + 'densenet169_weights_tf_dim_ordering_tf_kernels.h5')\n","DENSENET169_WEIGHT_PATH_NO_TOP = (\n","    BASE_WEIGTHS_PATH +\n","    'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5')\n","DENSENET201_WEIGHT_PATH = (\n","    BASE_WEIGTHS_PATH + 'densenet201_weights_tf_dim_ordering_tf_kernels.h5')\n","DENSENET201_WEIGHT_PATH_NO_TOP = (\n","    BASE_WEIGTHS_PATH +\n","    'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5')\n","\n","layers = VersionAwareLayers()\n","\n","\n","def dense_block(x, blocks, name):\n","  \"\"\"A dense block.\n","  Arguments:\n","    x: input tensor.\n","    blocks: integer, the number of building blocks.\n","    name: string, block label.\n","  Returns:\n","    Output tensor for the block.\n","  \"\"\"\n","  for i in range(blocks):\n","    x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n","  return x\n","\n","\n","def transition_block(x, reduction, name):\n","  \"\"\"A transition block.\n","  Arguments:\n","    x: input tensor.\n","    reduction: float, compression rate at transition layers.\n","    name: string, block label.\n","  Returns:\n","    output tensor for the block.\n","  \"\"\"\n","  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n","  x = layers.BatchNormalization(\n","      axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')(\n","          x)\n","  x = layers.Activation('relu', name=name + '_relu')(x)\n","  x = layers.Conv2D(\n","      int(backend.int_shape(x)[bn_axis] * reduction),\n","      1,\n","      use_bias=False,\n","      name=name + '_conv')(\n","          x)\n","  x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n","  return x\n","\n","\n","def conv_block(x, growth_rate, name):\n","  \"\"\"A building block for a dense block.\n","  Arguments:\n","    x: input tensor.\n","    growth_rate: float, growth rate at dense layers.\n","    name: string, block label.\n","  Returns:\n","    Output tensor for the block.\n","  \"\"\"\n","  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n","  x1 = layers.BatchNormalization(\n","      axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(\n","          x)\n","  x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n","  x1 = layers.Conv2D(\n","      4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(\n","          x1)\n","  x1 = layers.BatchNormalization(\n","      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(\n","          x1)\n","  x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n","  x1 = layers.Conv2D(\n","      growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(\n","          x1)\n","  x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n","  return x\n","\n","#DenseNet121일 경우,\n","# DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n","#                   input_shape, pooling, classes)\n","def DenseNet(\n","    blocks, #[6, 12, 24, 16]\n","    include_top=True,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=None,\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation='softmax'):\n","  \"\"\"Instantiates the DenseNet architecture.\n","  Reference:\n","  - [Densely Connected Convolutional Networks](\n","      https://arxiv.org/abs/1608.06993) (CVPR 2017)\n","  Optionally loads weights pre-trained on ImageNet.\n","  Note that the data format convention used by the model is\n","  the one specified in your Keras config at `~/.keras/keras.json`.\n","  Note: each Keras Application expects a specific kind of input preprocessing.\n","  For DenseNet, call `tf.keras.applications.densenet.preprocess_input` on your\n","  inputs before passing them to the model.\n","  Arguments:\n","    blocks: numbers of building blocks for the four dense layers.\n","    include_top: whether to include the fully-connected\n","      layer at the top of the network.\n","    weights: one of `None` (random initialization),\n","      'imagenet' (pre-training on ImageNet),\n","      or the path to the weights file to be loaded.\n","    input_tensor: optional Keras tensor\n","      (i.e. output of `layers.Input()`)\n","      to use as image input for the model.\n","    input_shape: optional shape tuple, only to be specified\n","      if `include_top` is False (otherwise the input shape\n","      has to be `(224, 224, 3)` (with `'channels_last'` data format)\n","      or `(3, 224, 224)` (with `'channels_first'` data format).\n","      It should have exactly 3 inputs channels,\n","      and width and height should be no smaller than 32.\n","      E.g. `(200, 200, 3)` would be one valid value.\n","    pooling: optional pooling mode for feature extraction\n","      when `include_top` is `False`.\n","      - `None` means that the output of the model will be\n","          the 4D tensor output of the\n","          last convolutional block.\n","      - `avg` means that global average pooling\n","          will be applied to the output of the\n","          last convolutional block, and thus\n","          the output of the model will be a 2D tensor.\n","      - `max` means that global max pooling will\n","          be applied.\n","    classes: optional number of classes to classify images\n","      into, only to be specified if `include_top` is True, and\n","      if no `weights` argument is specified.\n","    classifier_activation: A `str` or callable. The activation function to use\n","      on the \"top\" layer. Ignored unless `include_top=True`. Set\n","      `classifier_activation=None` to return the logits of the \"top\" layer.\n","  Returns:\n","    A `keras.Model` instance.\n","  Raises:\n","    ValueError: in case of invalid argument for `weights`,\n","      or invalid input shape.\n","    ValueError: if `classifier_activation` is not `softmax` or `None` when\n","      using a pretrained top layer.\n","  \"\"\"\n","  if not (weights in {'imagenet', None} or file_io.file_exists_v2(weights)):\n","    raise ValueError('The `weights` argument should be either '\n","                     '`None` (random initialization), `imagenet` '\n","                     '(pre-training on ImageNet), '\n","                     'or the path to the weights file to be loaded.')\n","\n","  if weights == 'imagenet' and include_top and classes != 1000:\n","    raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n","                     ' as true, `classes` should be 1000')\n","\n","  # Determine proper input shape\n","  input_shape = imagenet_utils.obtain_input_shape(\n","      input_shape,\n","      default_size=224,\n","      min_size=32,\n","      data_format=backend.image_data_format(),\n","      require_flatten=include_top,\n","      weights=weights)\n","\n","  if input_tensor is None:\n","    img_input = layers.Input(shape=input_shape)\n","  else:\n","    if not backend.is_keras_tensor(input_tensor):\n","      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n","    else:\n","      img_input = input_tensor\n","\n","  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n","\n","#특징 추출 부분 시작 \n","  x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n","  x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n","  #배치 정규화\n","  x = layers.BatchNormalization(\n","      axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(\n","          x)\n","  x = layers.Activation('relu', name='conv1/relu')(x)\n","  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n","  x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n","\n","  #densenet121일 경우, block내 denselayer 6개\n","  x = dense_block(x, blocks[0], name='conv2')\n","  x = transition_block(x, 0.5, name='pool2') # transition_block 생성함수 \n","  #densenet121일 경우, block내 denselayer 12개\n","  x = dense_block(x, blocks[1], name='conv3')\n","  x = transition_block(x, 0.5, name='pool3')\n","  #densenet121일 경우, block내 denselayer 24개\n","  x = dense_block(x, blocks[2], name='conv4')\n","  x = transition_block(x, 0.5, name='pool4')\n","  #densenet121일 경우, block내 denselayer 16개\n","  x = dense_block(x, blocks[3], name='conv5')\n","\n","  x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n","  x = layers.Activation('relu', name='relu')(x)\n","\n","  #분류 층 포함할 경우 \n","  if include_top:\n","    #Global Average Pooling layer\n","    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n","\n","    imagenet_utils.validate_activation(classifier_activation, weights)\n","    #클래스 개수에 맞게 최종 분류 \n","    x = layers.Dense(classes, activation=classifier_activation, # activation function 은 softmax 사용\n","                     name='predictions')(x)\n","  else:\n","    if pooling == 'avg':\n","      x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n","    elif pooling == 'max':\n","      x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n","\n","  # Ensure that the model takes into account\n","  # any potential predecessors of `input_tensor`.\n","  if input_tensor is not None:\n","    inputs = layer_utils.get_source_inputs(input_tensor)\n","  else:\n","    inputs = img_input\n","\n","  #종류에 맞게 이름 설정 \n","  # Create model.\n","  if blocks == [6, 12, 24, 16]:\n","    model = training.Model(inputs, x, name='densenet121')\n","  elif blocks == [6, 12, 32, 32]:\n","    model = training.Model(inputs, x, name='densenet169')\n","  elif blocks == [6, 12, 48, 32]:\n","    model = training.Model(inputs, x, name='densenet201')\n","  else:\n","    model = training.Model(inputs, x, name='densenet')\n","\n","  # Load weights.\n","  #분류층 포함 여부에 따라서 가중치 로드 \n","  if weights == 'imagenet':\n","    if include_top:\n","      if blocks == [6, 12, 24, 16]:\n","        weights_path = data_utils.get_file(\n","            'densenet121_weights_tf_dim_ordering_tf_kernels.h5',\n","            DENSENET121_WEIGHT_PATH,\n","            cache_subdir='models',\n","            file_hash='9d60b8095a5708f2dcce2bca79d332c7')\n","      elif blocks == [6, 12, 32, 32]:\n","        weights_path = data_utils.get_file(\n","            'densenet169_weights_tf_dim_ordering_tf_kernels.h5',\n","            DENSENET169_WEIGHT_PATH,\n","            cache_subdir='models',\n","            file_hash='d699b8f76981ab1b30698df4c175e90b')\n","      elif blocks == [6, 12, 48, 32]:\n","        weights_path = data_utils.get_file(\n","            'densenet201_weights_tf_dim_ordering_tf_kernels.h5',\n","            DENSENET201_WEIGHT_PATH,\n","            cache_subdir='models',\n","            file_hash='1ceb130c1ea1b78c3bf6114dbdfd8807')\n","    else:\n","      if blocks == [6, 12, 24, 16]:\n","        weights_path = data_utils.get_file(\n","            'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","            DENSENET121_WEIGHT_PATH_NO_TOP,\n","            cache_subdir='models',\n","            file_hash='30ee3e1110167f948a6b9946edeeb738')\n","      elif blocks == [6, 12, 32, 32]:\n","        weights_path = data_utils.get_file(\n","            'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","            DENSENET169_WEIGHT_PATH_NO_TOP,\n","            cache_subdir='models',\n","            file_hash='b8c4d4c20dd625c148057b9ff1c1176b')\n","      elif blocks == [6, 12, 48, 32]:\n","        weights_path = data_utils.get_file(\n","            'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","            DENSENET201_WEIGHT_PATH_NO_TOP,\n","            cache_subdir='models',\n","            file_hash='c13680b51ded0fb44dff2d8f86ac8bb1')\n","    model.load_weights(weights_path)\n","  elif weights is not None:\n","    model.load_weights(weights)\n","\n","  return model\n","\n","#DenseNet 호출 시 종류에 따라 처음 호출되는 함수들 \n","@keras_export('keras.applications.densenet.DenseNet121',\n","              'keras.applications.DenseNet121')\n","def DenseNet121(include_top=True,\n","                weights='imagenet',\n","                input_tensor=None,\n","                input_shape=None,\n","                pooling=None,\n","                classes=1000):\n","  \"\"\"Instantiates the Densenet121 architecture.\"\"\"\n","  #DenseNet 함수 호출 \n","  return DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n","                  input_shape, pooling, classes)\n","\n","\n","@keras_export('keras.applications.densenet.DenseNet169',\n","              'keras.applications.DenseNet169')\n","def DenseNet169(include_top=True,\n","                weights='imagenet',\n","                input_tensor=None,\n","                input_shape=None,\n","                pooling=None,\n","                classes=1000):\n","  \"\"\"Instantiates the Densenet169 architecture.\"\"\"\n","  return DenseNet([6, 12, 32, 32], include_top, weights, input_tensor,\n","                  input_shape, pooling, classes)\n","\n","\n","@keras_export('keras.applications.densenet.DenseNet201',\n","              'keras.applications.DenseNet201')\n","def DenseNet201(include_top=True,\n","                weights='imagenet',\n","                input_tensor=None,\n","                input_shape=None,\n","                pooling=None,\n","                classes=1000):\n","  \"\"\"Instantiates the Densenet201 architecture.\"\"\"\n","  return DenseNet([6, 12, 48, 32], include_top, weights, input_tensor,\n","                  input_shape, pooling, classes)\n","\n","\n","@keras_export('keras.applications.densenet.preprocess_input')\n","def preprocess_input(x, data_format=None):\n","  return imagenet_utils.preprocess_input(\n","      x, data_format=data_format, mode='torch')\n","\n","\n","@keras_export('keras.applications.densenet.decode_predictions')\n","def decode_predictions(preds, top=5):\n","  return imagenet_utils.decode_predictions(preds, top=top)\n","\n","\n","preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n","    mode='',\n","    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TORCH,\n","    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)\n","decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n","\n","DOC = \"\"\"\n","  Reference:\n","  - [Densely Connected Convolutional Networks](\n","      https://arxiv.org/abs/1608.06993) (CVPR 2017)\n","  Optionally loads weights pre-trained on ImageNet.\n","  Note that the data format convention used by the model is\n","  the one specified in your Keras config at `~/.keras/keras.json`.\n","  Note: each Keras Application expects a specific kind of input preprocessing.\n","  For DenseNet, call `tf.keras.applications.densenet.preprocess_input` on your\n","  inputs before passing them to the model.\n","  Arguments:\n","    include_top: whether to include the fully-connected\n","      layer at the top of the network.\n","    weights: one of `None` (random initialization),\n","      'imagenet' (pre-training on ImageNet),\n","      or the path to the weights file to be loaded.\n","    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n","      to use as image input for the model.\n","    input_shape: optional shape tuple, only to be specified\n","      if `include_top` is False (otherwise the input shape\n","      has to be `(224, 224, 3)` (with `'channels_last'` data format)\n","      or `(3, 224, 224)` (with `'channels_first'` data format).\n","      It should have exactly 3 inputs channels,\n","      and width and height should be no smaller than 32.\n","      E.g. `(200, 200, 3)` would be one valid value.\n","    pooling: Optional pooling mode for feature extraction\n","      when `include_top` is `False`.\n","      - `None` means that the output of the model will be\n","          the 4D tensor output of the\n","          last convolutional block.\n","      - `avg` means that global average pooling\n","          will be applied to the output of the\n","          last convolutional block, and thus\n","          the output of the model will be a 2D tensor.\n","      - `max` means that global max pooling will\n","          be applied.\n","    classes: optional number of classes to classify images\n","      into, only to be specified if `include_top` is True, and\n","      if no `weights` argument is specified.\n","  Returns:\n","    A Keras model instance.\n","\"\"\"\n","\n","setattr(DenseNet121, '__doc__', DenseNet121.__doc__ + DOC)\n","setattr(DenseNet169, '__doc__', DenseNet169.__doc__ + DOC)\n","setattr(DenseNet201, '__doc__', DenseNet201.__doc__ + DOC)"]},{"cell_type":"code","source":[],"metadata":{"id":"LaTNQT1EkUpE"},"execution_count":null,"outputs":[]}]}