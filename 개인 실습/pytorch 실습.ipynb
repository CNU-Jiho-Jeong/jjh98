{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5e5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601a8fd",
   "metadata": {},
   "source": [
    "# 파이토치\n",
    "\n",
    "### - 파이썬 기반의 과학 연산 패키지로, 다음과 같은 두 집단을 대상으로 한다\n",
    "\n",
    "- 넘파이를 대체하면서 GPU를 이용한 연산이 필요한 경우\n",
    "- 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24059594",
   "metadata": {},
   "source": [
    "Tensor는 넘파이의 ndarray와 유사하며, 추가로 GPU를 사용한 연산 가속도 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c114bdea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ac43b",
   "metadata": {},
   "source": [
    "초기화 되지 않은 5X3 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3140ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.9082e-39, 8.4489e-39, 9.6429e-39],\n",
      "        [8.4490e-39, 9.6429e-39, 9.2755e-39],\n",
      "        [1.0286e-38, 9.0919e-39, 8.9082e-39],\n",
      "        [9.2755e-39, 8.4490e-39, 1.0194e-38],\n",
      "        [9.0919e-39, 8.4490e-39, 9.6429e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3) # empty: 주어진 크기의 아무값으로도 초기화 되지 않은 행렬을 만든다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd06e51",
   "metadata": {},
   "source": [
    "무작위로 초기화된 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644c0e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5363,  0.9238, -0.3825],\n",
      "        [-0.6361,  0.6469,  0.2539],\n",
      "        [-1.7714, -2.2074, -0.2647],\n",
      "        [ 0.3151, -0.4068, -1.0721],\n",
      "        [-1.0829, -0.4313,  1.5984]])\n",
      "tensor([[0.7040, 0.1925, 0.9610],\n",
      "        [0.5229, 0.8682, 0.4386],\n",
      "        [0.6393, 0.3721, 0.4975],\n",
      "        [0.3843, 0.8387, 0.7109],\n",
      "        [0.6475, 0.3094, 0.1169]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5,3) #표준정규분포에서 샘플링\n",
    "print(x)\n",
    "x = torch.rand(5,3) #0에서 1사이의 값\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48da4c7a",
   "metadata": {},
   "source": [
    "dtype이 long이고 0으로 채워진 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c81d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8fda0",
   "metadata": {},
   "source": [
    "dtype이 long이고 1로 채워진 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdfe18fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a787c1",
   "metadata": {},
   "source": [
    "데이터로부터 tensor를 직접 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3daef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bc488",
   "metadata": {},
   "source": [
    "또는 존재하는 tensor를 바탕으로 tensor를 만들 수 있음.\n",
    "이 메소드들은 사용자로부터 제공된 새로운 값이 없는 한, 입력 tensor의 속성들(dtype)을 재사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed310c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.0164,  0.9076, -0.0872],\n",
      "        [-0.0461, -0.6181,  0.6720],\n",
      "        [ 1.3140,  0.9666, -1.4907],\n",
      "        [-0.1990,  0.3570, -0.1000],\n",
      "        [-0.8772,  2.1490, -1.5631]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype = torch.double)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float) # torch.rand_like(tensor, dtype=~~): 파라미터로 들어간 tensor 객체의 사이즈와 똑같은 행렬을 반환, 요소들은 정규분포 그래프 상의 랜덤한 값으로 초기화되어있음.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdca642",
   "metadata": {},
   "source": [
    "행렬의 크기를 구하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c42931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size()) \n",
    "print(x.shape)\n",
    "# 둘 중 아무거나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1779991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0164,  0.9076, -0.0872],\n",
      "        [-0.0461, -0.6181,  0.6720],\n",
      "        [ 1.3140,  0.9666, -1.4907],\n",
      "        [-0.1990,  0.3570, -0.1000],\n",
      "        [-0.8772,  2.1490, -1.5631]])\n",
      "tensor([[0.5866, 0.7566, 0.3453],\n",
      "        [0.6391, 0.3180, 0.0856],\n",
      "        [0.9312, 0.4020, 0.3390],\n",
      "        [0.3510, 0.4924, 0.7561],\n",
      "        [0.7865, 0.5928, 0.7375]])\n",
      "tensor([[ 0.5702,  1.6642,  0.2581],\n",
      "        [ 0.5930, -0.3000,  0.7576],\n",
      "        [ 2.2452,  1.3685, -1.1516],\n",
      "        [ 0.1520,  0.8494,  0.6561],\n",
      "        [-0.0907,  2.7417, -0.8256]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈\n",
    "y = torch.rand(5,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87726c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5702,  1.6642,  0.2581],\n",
      "        [ 0.5930, -0.3000,  0.7576],\n",
      "        [ 2.2452,  1.3685, -1.1516],\n",
      "        [ 0.1520,  0.8494,  0.6561],\n",
      "        [-0.0907,  2.7417, -0.8256]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈 2\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "026fa4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0164,  0.9076, -0.0872],\n",
      "        [-0.0461, -0.6181,  0.6720],\n",
      "        [ 1.3140,  0.9666, -1.4907],\n",
      "        [-0.1990,  0.3570, -0.1000],\n",
      "        [-0.8772,  2.1490, -1.5631]])\n",
      "tensor([[ 0.5702,  1.6642,  0.2581],\n",
      "        [ 0.5930, -0.3000,  0.7576],\n",
      "        [ 2.2452,  1.3685, -1.1516],\n",
      "        [ 0.1520,  0.8494,  0.6561],\n",
      "        [-0.0907,  2.7417, -0.8256]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "print(result)\n",
    "\n",
    "torch.add(x,y, out=result) # 더한값(결과값)이 result 텐서로 들어감\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b74f33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5866, 0.7566, 0.3453],\n",
      "        [0.6391, 0.3180, 0.0856],\n",
      "        [0.9312, 0.4020, 0.3390],\n",
      "        [0.3510, 0.4924, 0.7561],\n",
      "        [0.7865, 0.5928, 0.7375]])\n",
      "tensor([[ 0.5702,  1.6642,  0.2581],\n",
      "        [ 0.5930, -0.3000,  0.7576],\n",
      "        [ 2.2452,  1.3685, -1.1516],\n",
      "        [ 0.1520,  0.8494,  0.6561],\n",
      "        [-0.0907,  2.7417, -0.8256]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈 바꿔치기\n",
    "print(y)\n",
    "y.add_(x) # 바꿔치기 방식으로 tensor 값을 변경하는 연산은 _를 접미사로 갖는다.\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08212d81",
   "metadata": {},
   "source": [
    "tensor의 크기(size)나 모양(shape)을 변경하고 싶다면 torch.view를 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acead5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9463, -1.1457,  2.8078, -1.7477],\n",
      "        [ 1.0347,  1.2281, -0.7785, -0.6267],\n",
      "        [-0.3043,  0.4715,  0.9932, -0.8581],\n",
      "        [ 0.0873, -1.4072, -1.7428, -0.8393]])\n",
      "tensor([-0.9463, -1.1457,  2.8078, -1.7477,  1.0347,  1.2281, -0.7785, -0.6267,\n",
      "        -0.3043,  0.4715,  0.9932, -0.8581,  0.0873, -1.4072, -1.7428, -0.8393])\n",
      "tensor([[-0.9463, -1.1457],\n",
      "        [ 2.8078, -1.7477],\n",
      "        [ 1.0347,  1.2281],\n",
      "        [-0.7785, -0.6267],\n",
      "        [-0.3043,  0.4715],\n",
      "        [ 0.9932, -0.8581],\n",
      "        [ 0.0873, -1.4072],\n",
      "        [-1.7428, -0.8393]])\n",
      "torch.Size([16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "\n",
    "y = x.view(16) # 16개의 차원을 가지는 벡터의 형태로 늘린다.\n",
    "z = y.view(-1,2) # -1: 남는 원소를 자동으로 차원을 결정해서 넣어주어라. 2: 원소의 개수가 16개이므로 두 개씩 8개가 자동으로 들어감.(8,2)\n",
    "print(y)\n",
    "print(z)\n",
    "print(y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbf8b4",
   "metadata": {},
   "source": [
    "만약 tensor에 하나의 값만 존재한다면, .item()을 사용하면 숫자값을 얻을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4414e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3401])\n",
      "<class 'torch.Tensor'> <class 'float'>\n",
      "-0.3401394486427307\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(type(x), type(x.item()))\n",
    "print(x.item()) # 숫자값 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc635fc6",
   "metadata": {},
   "source": [
    "파이토치 홈페이지에 전치, 인덱싱, 슬라이싱 등의 연산이 나와있으니 필요할 때 찾아볼것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866ad45",
   "metadata": {},
   "source": [
    "넘파이 변환\n",
    "- Torch Tensor를 넘파이 배열(array)로 변환하거나, 그 반대로 하는 것은 매우 쉽다.\n",
    "- Torch Tensor와 넘파이 배열은 하나를 변경하면 다른 하나도 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02ad4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor -> 넘파이배열\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "747ffef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy() # 넘파이 배열로 변환\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c9b08",
   "metadata": {},
   "source": [
    ".to 메서드를 사용해 Tensor를 어떠한 장치로도 옮길 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "......\n",
    "device = \"cuda:0\"\n",
    "x = x.to(device)\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36104aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=95d0231541ba31c5f6032de6fdd3549ae8e87fc87e4de297f4485434b38e5078\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c29159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a87a5",
   "metadata": {},
   "source": [
    "변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8112cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable(~~~~)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa382f",
   "metadata": {},
   "source": [
    "텐서플로 그래프에서 tf.Variable의 값을 사용하려면 이를 단순히 tf.Tensor로 취급하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39931811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(0,0) # v 생성\n",
    "print(v)\n",
    "\n",
    "w = v+1 # w는 v값 기준으로 계산되는 tf.Tensor 이다. 변수가 수식에 사용될 때(여기서는 v+1), 변수는 자동적으로 tf.Tensor로 변환되어 값을 표현한다. \n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "252307f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값을 변수에 할당하려면 assign, assign_add 메소드 활용\n",
    "a = tf.Variable(0,0)\n",
    "a.assign_add(1)\n",
    "a.read_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc50b3",
   "metadata": {},
   "source": [
    "tf.Tensor 객체의 랭크는 그 차원의 수\n",
    "\n",
    "- 랭크 0 : 값 자체\n",
    "- 랭크 1 : 벡터\n",
    "- 고차원 랭크: 랭크2는 최소 한 개 이상의 열과 행으로 구성된다.\n",
    "- tf.rank(객체): 객체의 랭크 구하기\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc05d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Tensor 객체 형태 얻기 -> 객체.shape 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5383a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Tensor 형태 변경 =>  파이토치의 view와 굉장히 유사함. 참조할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76005a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
